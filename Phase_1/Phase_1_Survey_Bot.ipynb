{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey Bot - Phase 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Question_Text</th>\n",
       "      <th>Options_(if_applicable)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Fill-in-the-blank</td>\n",
       "      <td>How many days a week do you walk?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>Do you drink tea?</td>\n",
       "      <td>Yes,No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>How often do you eat fish?</td>\n",
       "      <td>Daily,Weekly,Monthly,Never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>Fill-in-the-blank</td>\n",
       "      <td>How many days a week do you drink alcohol?</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>How many hours do you sleep?</td>\n",
       "      <td>5 hrs,6 hrs,8 hrs,10 hrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question_ID      Question_Type                               Question_Text  \\\n",
       "0          Q1  Fill-in-the-blank           How many days a week do you walk?   \n",
       "1          Q2    Multiple Choice                           Do you drink tea?   \n",
       "2          Q3    Multiple Choice                  How often do you eat fish?   \n",
       "3          Q4  Fill-in-the-blank  How many days a week do you drink alcohol?   \n",
       "4          Q5    Multiple Choice                How many hours do you sleep?   \n",
       "\n",
       "      Options_(if_applicable)  \n",
       "0                           -  \n",
       "1                      Yes,No  \n",
       "2  Daily,Weekly,Monthly,Never  \n",
       "3                           -  \n",
       "4    5 hrs,6 hrs,8 hrs,10 hrs  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Excel file\n",
    "qn_display = pd.read_excel(\"/Users/admin/ai-questionnaire-project/excel_qns.xlsx\")  # Replace with your actual file path\n",
    "# Fill NaN with empty strings\n",
    "qn_display.fillna('', inplace=True)\n",
    "\n",
    "# Display DataFrame\n",
    "display(qn_display)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kannada STT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drink alcohol two days a week. I drink tea and eat fish three times a week, I sleep for 5 hours.\n",
    "# /Users/admin/ai-questionnaire-project/audio_phase_1.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STT Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select input type:\n",
      "1. Audio File\n",
      "2. Live Audio\n",
      "3. Text Input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Converting audio file: /Users/admin/ai-questionnaire-project/flask_test_demo_audio.mp3\n",
      "INFO:root:Running SpeechRecognition for transcription\n",
      "INFO:root:Transcription result: ನಾನು ವಾರದಲ್ಲಿ ಎರಡು ದಿನ ಮದ್ಯಪಾನ ಮಾಡುತ್ತೇನೆ ನಾನು ಚಹಾ ಕುಡಿಯುತ್ತೇನೆ ಮತ್ತು ವಾರಕ್ಕೆ ಮೂರು ಬಾರಿ ಮೀನು ತಿನ್ನುತ್ತೇನೆ ನಾನು ಐದು ಗಂಟೆಗಳ ಕಾಲ ಮಲಗುತ್ತೇನೆ\n",
      "/opt/anaconda3/envs/ai-questionnaire/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "INFO:root:Output saved to output.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results ---\n",
      "Kannada Text: ನಾನು ವಾರದಲ್ಲಿ ಎರಡು ದಿನ ಮದ್ಯಪಾನ ಮಾಡುತ್ತೇನೆ ನಾನು ಚಹಾ ಕುಡಿಯುತ್ತೇನೆ ಮತ್ತು ವಾರಕ್ಕೆ ಮೂರು ಬಾರಿ ಮೀನು ತಿನ್ನುತ್ತೇನೆ ನಾನು ಐದು ಗಂಟೆಗಳ ಕಾಲ ಮಲಗುತ್ತೇನೆ\n",
      "English Translation: I drink alcohol two days a week, I drink tea and eat fish three times a week, I sleep for five hours.\n",
      "\n",
      "--- Stored Results ---\n",
      "Stored Kannada Text: ನಾನು ವಾರದಲ್ಲಿ ಎರಡು ದಿನ ಮದ್ಯಪಾನ ಮಾಡುತ್ತೇನೆ ನಾನು ಚಹಾ ಕುಡಿಯುತ್ತೇನೆ ಮತ್ತು ವಾರಕ್ಕೆ ಮೂರು ಬಾರಿ ಮೀನು ತಿನ್ನುತ್ತೇನೆ ನಾನು ಐದು ಗಂಟೆಗಳ ಕಾಲ ಮಲಗುತ್ತೇನೆ\n",
      "Stored English Translation: I drink alcohol two days a week, I drink tea and eat fish three times a week, I sleep for five hours.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import logging\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig, AutoTokenizer\n",
    "from IndicTransToolkit import IndicProcessor\n",
    "import threading\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load IndicTrans model and tokenizer\n",
    "MODEL_NAME = \"ai4bharat/indictrans2-indic-en-1B\"\n",
    "config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "indic_en_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "indic_en_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "ip = IndicProcessor(inference=True)\n",
    "\n",
    "# Global variables to store output\n",
    "stored_kannada_text = None\n",
    "stored_english_translation = None\n",
    "\n",
    "# ✅ Convert audio to WAV format using pydub\n",
    "def convert_to_wav(audio_file):\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        temp_wav_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "        audio.export(temp_wav_file.name, format=\"wav\")\n",
    "        return temp_wav_file.name\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting file to WAV: {e}\")\n",
    "        return None\n",
    "\n",
    "# ✅ Function to transcribe Kannada audio\n",
    "def transcribe_audio(audio_file):\n",
    "    try:\n",
    "        logging.info(f\"Converting audio file: {audio_file}\")\n",
    "        converted_file = convert_to_wav(audio_file)\n",
    "        if not converted_file:\n",
    "            return \"Error converting audio file to WAV\"\n",
    "\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(converted_file) as source:\n",
    "            audio = recognizer.record(source)\n",
    "\n",
    "        logging.info(\"Running SpeechRecognition for transcription\")\n",
    "        transcription = recognizer.recognize_google(audio, language=\"kn-IN\")\n",
    "        logging.info(f\"Transcription result: {transcription}\")\n",
    "\n",
    "        os.remove(converted_file)  # Remove temporary file after processing\n",
    "        return transcription.strip()\n",
    "    except sr.UnknownValueError:\n",
    "        logging.error(\"SpeechRecognition could not understand the audio\")\n",
    "        return \"Could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        logging.error(f\"SpeechRecognition service error: {e}\")\n",
    "        return f\"SpeechRecognition error: {e}\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during transcription: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# ✅ Function to translate Kannada to English using IndicTrans\n",
    "def translate_sentence(sentence):\n",
    "    try:\n",
    "        src_lang, tgt_lang = \"kan_Knda\", \"eng_Latn\"\n",
    "        batch = [sentence]\n",
    "\n",
    "        # Preprocess input\n",
    "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "\n",
    "        # Tokenize input\n",
    "        inputs = indic_en_tokenizer(\n",
    "            batch,\n",
    "            truncation=True,\n",
    "            padding=\"longest\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "        # Generate translation\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = indic_en_model.generate(\n",
    "                **inputs,\n",
    "                use_cache=True,\n",
    "                min_length=0,\n",
    "                max_length=256,\n",
    "                num_beams=5,\n",
    "                num_return_sequences=1,\n",
    "            )\n",
    "\n",
    "        # Decode output\n",
    "        with indic_en_tokenizer.as_target_tokenizer():\n",
    "            generated_tokens = indic_en_tokenizer.batch_decode(\n",
    "                generated_tokens.detach().cpu().tolist(),\n",
    "                skip_special_tokens=True,\n",
    "                clean_up_tokenization_spaces=True,\n",
    "            )\n",
    "\n",
    "        # Post-process result\n",
    "        translations = ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
    "        return translations[0] if translations else \"Translation failed.\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during translation: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def transcribe_audio_from_mic(language='kn-IN'):\n",
    "    recognizer = sr.Recognizer()\n",
    "    recognizer.dynamic_energy_threshold = True\n",
    "    recognizer.pause_threshold = 1.0\n",
    "    \n",
    "    stop_event = threading.Event()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording... Speak now!\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "        audio_data = []\n",
    "        start_time = time.time()  # Start time tracking\n",
    "\n",
    "        def stop_recording():\n",
    "            input(\"Press Enter to stop recording...\\n\")\n",
    "            stop_event.set()\n",
    "\n",
    "        stop_thread = threading.Thread(target=stop_recording)\n",
    "        stop_thread.start()\n",
    "\n",
    "        try:\n",
    "            while not stop_event.is_set():\n",
    "                audio = recognizer.listen(source)\n",
    "                audio_data.append(audio)\n",
    "\n",
    "            end_time = time.time()  # End time tracking\n",
    "            duration = round(end_time - start_time, 2)  # Calculate duration in seconds\n",
    "\n",
    "            print(f\"Recording duration: {duration} seconds\")\n",
    "\n",
    "            if not audio_data:\n",
    "                print(\"No audio captured.\")\n",
    "                return None, duration\n",
    "\n",
    "            # Combine the audio chunks\n",
    "            combined_audio = sr.AudioData(\n",
    "                b''.join([a.get_raw_data() for a in audio_data]),\n",
    "                source.SAMPLE_RATE,\n",
    "                source.SAMPLE_WIDTH\n",
    "            )\n",
    "\n",
    "            # Attempt transcription\n",
    "            try:\n",
    "                text = recognizer.recognize_google(combined_audio, language=language)\n",
    "                print(\"Transcription:\", text)\n",
    "                return text, duration\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Speech Recognition could not understand the audio.\")\n",
    "                return None, 0\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"Could not request results: {e}\")\n",
    "                return None, 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None, 0\n",
    "        finally:\n",
    "            stop_event.set()\n",
    "            stop_thread.join()\n",
    "\n",
    "# ✅ Function to process input\n",
    "def process_input(input_type, audio_file=None, text_input=None):\n",
    "    if input_type == \"1\" and audio_file:\n",
    "        kannada_text = transcribe_audio(audio_file)\n",
    "    elif input_type == \"2\":\n",
    "        transcription, duration = transcribe_audio_from_mic(language='kn-IN')\n",
    "\n",
    "        if transcription:\n",
    "            kannada_text = transcription\n",
    "        else:\n",
    "            return \"Could not transcribe live audio\", \"No translation\"\n",
    "        \n",
    "    elif input_type == \"3\" and text_input:\n",
    "        kannada_text = text_input\n",
    "    else:\n",
    "        return \"Invalid input\", \"Invalid input\"\n",
    "    \n",
    "    # Ensure that kannada_text is a string (not a tuple)\n",
    "    if isinstance(kannada_text, tuple):\n",
    "        kannada_text = kannada_text[0]\n",
    "\n",
    "    english_translation = translate_sentence(kannada_text)\n",
    "    return kannada_text, english_translation\n",
    "\n",
    "# ✅ Save output to file\n",
    "def save_output_to_file(kannada_text, english_translation, file_path=\"output.txt\"):\n",
    "    try:\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Kannada Text:\\n{kannada_text}\\n\\n\")\n",
    "            f.write(f\"English Translation:\\n{english_translation}\\n\")\n",
    "        logging.info(f\"Output saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving output to file: {e}\")\n",
    "\n",
    "# ✅ Terminal-based input handling\n",
    "def main():\n",
    "    global stored_kannada_text, stored_english_translation\n",
    "    \n",
    "    print(\"\\nSelect input type:\")\n",
    "    print(\"1. Audio File\")\n",
    "    print(\"2. Live Audio\")\n",
    "    print(\"3. Text Input\")\n",
    "    choice = input(\"Enter your choice (1/2/3): \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        file_path = input(\"Enter path to the audio file: \").strip()\n",
    "        if not os.path.exists(file_path):\n",
    "            logging.error(f\"Invalid file path: {file_path}\")\n",
    "            print(\"File not found. Please check the path and try again.\")\n",
    "            return\n",
    "        kannada_text, english_translation = process_input(\"1\", audio_file=file_path)\n",
    "\n",
    "    elif choice == \"2\":\n",
    "        logging.info(\"Starting live audio capture...\")\n",
    "        kannada_text, english_translation = process_input(\"2\")\n",
    "\n",
    "    elif choice == \"3\":\n",
    "        text_input = input(\"Enter Kannada text: \").strip()\n",
    "        kannada_text, english_translation = process_input(\"3\", text_input=text_input)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid choice.\")\n",
    "        return\n",
    "\n",
    "    # Store results globally for later use\n",
    "    stored_kannada_text = kannada_text\n",
    "    stored_english_translation = english_translation\n",
    "\n",
    "    print(\"\\n--- Results ---\")\n",
    "    print(f\"Kannada Text: {kannada_text}\")\n",
    "    print(f\"English Translation: {english_translation}\")\n",
    "\n",
    "    # Save output to file\n",
    "    save_output_to_file(kannada_text, english_translation)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    # Display stored results for debugging or later use\n",
    "    print(\"\\n--- Stored Results ---\")\n",
    "    print(f\"Stored Kannada Text: {stored_kannada_text}\")\n",
    "    print(f\"Stored English Translation: {stored_english_translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I drink alcohol two days a week, I drink tea and eat fish three times a week, I sleep for five hours.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_english_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634d7bdd0baf4cb78b4e2e815c65305d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4505769494134526b7d87df7743546d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity: 93.12%\n",
      "✅ No mismatched keywords detected.\n"
     ]
    }
   ],
   "source": [
    "#accuracy (#gradio for full stt code of kannada- with speech recognition model for live audio)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load a multilingual model (supports Kannada and English)\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Original text\n",
    "original_text = \"\"\"I drink alcohol two days a week. I drink tea and eat fish three times a week, I sleep for 5 hours.\"\"\"\n",
    "\n",
    "\n",
    "#output from indictrans\n",
    "\n",
    "translated_text = \"\"\"\"I drink alcohol two days a week, I drink tea and eat fish three times a week, I sleep for five hours.\"\"\"\n",
    "\n",
    "\n",
    "# Encode both sentences to embeddings\n",
    "original_embedding = model.encode(original_text, convert_to_tensor=True)\n",
    "translated_embedding = model.encode(translated_text, convert_to_tensor=True)\n",
    "\n",
    "# Calculate semantic similarity\n",
    "semantic_similarity = util.pytorch_cos_sim(original_embedding, translated_embedding).item()\n",
    "\n",
    "# Keyword check (if needed)\n",
    "keywords = [\"no appetite\", \"vomit\", \"cold\", \"weak\"]\n",
    "flagged_keywords = [word for word in keywords if word in original_text.lower() and word not in translated_text.lower()]\n",
    "\n",
    "# Results\n",
    "print(f\"Semantic Similarity: {semantic_similarity * 100:.2f}%\")\n",
    "\n",
    "if flagged_keywords:\n",
    "    print(f\"⚠️ Mismatched Keywords: {', '.join(flagged_keywords)}\")\n",
    "else:\n",
    "    print(\"✅ No mismatched keywords detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA (question answer) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drink alcohol two days a week, I drink tea and eat fish three times a week, I sleep for five hours.\n",
      "Do you drink tea? I drink tea ['Yes', 'No']\n",
      "How often do you eat fish? three times a week ['Daily', 'Weekly', 'Monthly', 'Never']\n",
      "How many days a week do you drink alcohol? two -\n",
      "Updated questionnaire saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Question_Type</th>\n",
       "      <th>Question_Text</th>\n",
       "      <th>Options_(if_applicable)</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Fill-in-the-blank</td>\n",
       "      <td>How many days a week do you walk?</td>\n",
       "      <td>-</td>\n",
       "      <td>No Answer found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>Do you drink tea?</td>\n",
       "      <td>Yes,No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>How often do you eat fish?</td>\n",
       "      <td>Daily,Weekly,Monthly,Never</td>\n",
       "      <td>Weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>Fill-in-the-blank</td>\n",
       "      <td>How many days a week do you drink alcohol?</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>How many hours do you sleep?</td>\n",
       "      <td>5 hrs,6 hrs,8 hrs,10 hrs</td>\n",
       "      <td>❗Engineer intervention required.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question_ID      Question_Type                               Question_Text  \\\n",
       "0          Q1  Fill-in-the-blank           How many days a week do you walk?   \n",
       "1          Q2    Multiple Choice                           Do you drink tea?   \n",
       "2          Q3    Multiple Choice                  How often do you eat fish?   \n",
       "3          Q4  Fill-in-the-blank  How many days a week do you drink alcohol?   \n",
       "4          Q5    Multiple Choice                How many hours do you sleep?   \n",
       "\n",
       "      Options_(if_applicable)                            Answer  \n",
       "0                           -                   No Answer found  \n",
       "1                      Yes,No                               Yes  \n",
       "2  Daily,Weekly,Monthly,Never                            Weekly  \n",
       "3                           -                                 2  \n",
       "4    5 hrs,6 hrs,8 hrs,10 hrs  ❗Engineer intervention required.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to extract the most relevant keyword (preferably a verb)\n",
    "def extract_main_keyword(question):\n",
    "    doc = nlp(question.lower())\n",
    "    \n",
    "    # Extract verbs first (action words)\n",
    "    verbs = [token.text for token in doc if token.pos_ == \"VERB\"]\n",
    "    \n",
    "    # If no verbs found, fall back to nouns\n",
    "    if verbs:\n",
    "        return verbs[0]  # Return the first verb found\n",
    "    else:\n",
    "        nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
    "        return nouns[0] if nouns else None  # Return first noun if exists, else None\n",
    "\n",
    "# Define file paths\n",
    "INPUT_FILE_PATH = os.path.expanduser(\"/Users/admin/ai-questionnaire-project/excel_qns.xlsx\")\n",
    "OUTPUT_FILE_PATH = os.path.expanduser(\"/Users/admin/ai-questionnaire-project/completed_qns.xlsx\")\n",
    "VOCAB_FILE = \"Final_vocab_dict.json\"\n",
    "\n",
    "# Load or create vocabulary\n",
    "def load_or_create_vocab():\n",
    "    if os.path.exists(VOCAB_FILE):\n",
    "        with open(VOCAB_FILE, \"r\") as f:\n",
    "            vocab = json.load(f)\n",
    "    else:\n",
    "        vocab = {\n",
    "            \"Options_yes_no\": {\n",
    "                \"valid_options\": [\"Yes\", \"No\"],  # List of valid Yes/No options\n",
    "                \"Yes\": [\"yes\", \"i do\", \"i drink\", \"i have\"],\n",
    "                \"No\": [\"no\", \"i don't\", \"i do not\", \"never\"]\n",
    "            },\n",
    "            \"Options_frequency\": {\n",
    "                \"valid_options\": [\"Daily\", \"Weekly\", \"Monthly\", \"Never\"],  # List of valid frequency options\n",
    "                \"Daily\": [\"daily\", \"a day\", \"every day\"],\n",
    "                \"Weekly\": [\"weekly\", \"a week\", \"every week\"],\n",
    "                \"Monthly\": [\"monthly\", \"a month\", \"once a month\"],\n",
    "                \"Never\": [\"never\", \"not at all\"]\n",
    "            },\n",
    "            \"num_mapping\": {\n",
    "                \"one\": \"1\", \"two\": \"2\", \"three\": \"3\", \"four\": \"4\", \"five\": \"5\",\n",
    "                \"six\": \"6\", \"seven\": \"7\", \"eight\": \"8\", \"nine\": \"9\", \"ten\": \"10\",\n",
    "                \"once\": \"1\", \"twice\": \"2\", \"thrice\": \"3\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(VOCAB_FILE, \"w\") as f:\n",
    "            json.dump(vocab, f, indent=4)\n",
    "    return vocab\n",
    "\n",
    "vocab = load_or_create_vocab()\n",
    "\n",
    "# Load Hugging Face QA model\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "# Load questionnaire from Excel\n",
    "def load_questionnaire(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=\"Questions\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load questionnaire. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert words to numbers using num_mapping\n",
    "def convert_numbers(answer):\n",
    "    words = answer.split()\n",
    "    for i, word in enumerate(words):\n",
    "        if word in vocab[\"num_mapping\"]:\n",
    "            words[i] = vocab[\"num_mapping\"][word]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Check if any exact key term from the question is in the transcription\n",
    "def should_extract_answer(question, transcription):\n",
    "    main_keyword = extract_main_keyword(question)\n",
    "    if main_keyword:\n",
    "        return main_keyword in transcription.lower()\n",
    "    return False\n",
    "\n",
    "# Extract answer using Hugging Face model\n",
    "def extract_answer_with_model(question, transcription):\n",
    "    try:\n",
    "        result = qa_pipeline(question=question, context=transcription)\n",
    "        return result['answer'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Model failed to extract answer: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process the predicted answer\n",
    "def process_answer(predicted_answer, options):\n",
    "    if not predicted_answer:\n",
    "        return \"No Answer Found\"\n",
    "    \n",
    "    answer = convert_numbers(predicted_answer.lower().strip())\n",
    "\n",
    "    if options == \"-\":\n",
    "        for key in [\"No\", \"Yes\"]:\n",
    "            if any(ans in answer for ans in vocab[\"Options_yes_no\"][key]):\n",
    "                return key\n",
    "            \n",
    "    if options == [\"Yes\",\"No\"]:\n",
    "        for key in [\"No\", \"Yes\"]:\n",
    "            if any(ans in answer for ans in vocab[\"Options_yes_no\"][key]):\n",
    "                return key\n",
    "    \n",
    "    elif options == [\"Daily\",\"Weekly\",\"Monthly\",\"Never\"]:\n",
    "        for key, values in vocab[\"Options_frequency\"].items():\n",
    "            if any(ans in answer for ans in values):\n",
    "                return key\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "# Fill answers in the questionnaire\n",
    "def fill_answers(df, transcription):\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['Question_Text']\n",
    "        question_type = row['Question_Type']\n",
    "        options = row['Options_(if_applicable)']\n",
    "        if options!='-':\n",
    "            options=options.split(\",\")\n",
    "        answer = \"No Answer found\"\n",
    "\n",
    "        if question_type == \"Multiple Choice\":\n",
    "            if options not in [vocab[\"Options_yes_no\"][\"valid_options\"], vocab[\"Options_frequency\"][\"valid_options\"]]:\n",
    "                answer = \"❗Engineer intervention required.\"\n",
    "                df.at[index, 'Answer'] = answer\n",
    "                continue  # Skip further processing and go to the next question\n",
    "        \n",
    "        if should_extract_answer(question, stored_english_translation):\n",
    "            predicted_answer = extract_answer_with_model(question, stored_english_translation)\n",
    "            print(question,predicted_answer,options)\n",
    "            processed_answer = process_answer(predicted_answer, options)\n",
    "            answer = processed_answer\n",
    "\n",
    "        df.at[index, 'Answer'] = answer\n",
    "    \n",
    "    return df\n",
    "print(stored_english_translation)\n",
    "# Load questionnaire\n",
    "df = load_questionnaire(INPUT_FILE_PATH)\n",
    "if df is not None:\n",
    "    df['Answer'] = \"No Answer\"\n",
    "    updated_df = fill_answers(df, stored_english_translation)\n",
    "    print(\"Updated questionnaire saved successfully!\")\n",
    "    display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-questionnaire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
