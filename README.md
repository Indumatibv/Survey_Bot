Survey Bot - PoC Documentation

ğŸ“Œ Overview

The Survey Bot Proof of Concept (PoC) aims to automate multilingual voice-based survey collection. This system is designed to handle complex conversational inputs in Kannada, Tamil, Malayalam, and English, transforming them into structured responses through speech recognition, translation, and contextual understanding.

ğŸ¯ Objective

To evaluate the feasibility of a real-time, multilingual, speech-driven survey bot by integrating:

Voice-based input capture.

Multilingual transcription and translation.

Contextual understanding of natural language.

Structured answer extraction from unstructured speech.

Phase 1: Capabilities Demonstrated

1. Speech Recognition

Handled Kannada input from:

ğŸ¤ Live Microphone
ğŸ“ Uploaded Audio Files
ğŸ“ Direct Text Input

Chosen Model:

speech_recognition (Google Web Speech API)

âœ… Fast and responsive for live transcription.

âŒ Whisper by OpenAI was rejected due to latency in real-time use.

2. Translation

Model Used: IndicTrans2 (ai4bharat/indictrans2-indic-en-1B).

âœ… Accurate Kannada-to-English translation.

âœ… Supports long and colloquial sentences.

3. Punctuation Restoration

Library: deepmultilingualpunctuation.

Restores punctuation for better structure and readability before feeding into downstream QA models.

4. Semantic Evaluation

Why Not Word Error Rate (WER)?

âŒ JiWER lacked contextual understanding.

Chosen Approach:

âœ… sentence-transformers for semantic similarity between generated and reference outputs.

5. Question Answering

Final Model: distilbert-base-cased-distilled-squad

âœ… Accurate answer extraction from long, translated responses.

âŒ Other models (T5, FLAN, Mistral) were less consistent or resource-heavy.

6. Custom Enhancements

Vocabulary Mapping: Ensures model responses align with predefined answer options.

Engineer Intervention Flag: Raised for new questions with unseen options.

Keyword Context Detection: Uses SpaCy to validate if relevant context is present.

Text Normalization: Converts textual numbers (e.g., â€œtwoâ€) to numerical equivalents (â€œ2â€).

ğŸ”„ Example Workflow

Input (Kannada Audio):
â€œà²¨à²¾à²¨à³ à²µà²¾à²°à²•à³à²•à³† à²à²°à²¡à³ à²¬à²¾à²°à²¿ à²®à²¦à³à²¯à²ªà²¾à²¨ à²®à²¾à²¡à³à²¤à³à²¤à³‡à²¨à³†â€¦â€

STT Output:
â€œI drink alcohol two times a weekâ€¦â€

QA Question: â€œHow many times a week do you consume alcohol?â€

Final Answer: "2"

If context is missing (e.g., no mention of â€œwalkâ€), system returns: â€œNo answer foundâ€

Dependency Versions-

| Domain            | Libraries / Tools Used                                                                                  |
| ----------------- | ------------------------------------------------------------------------------------------------------- |
| Speech Processing | `speech_recognition`, `pydub`, `scipy.io.wavfile`                                                       |
| NLP / ML          | `transformers`, `sentence-transformers`, `IndicTrans2`, `deepmultilingualpunctuation`, `spacy`, `torch` |
| Utilities         | `tempfile`, `os`, `threading`, `json`, `pandas`, `numpy`                                                |

âœ… Outcome

The PoC demonstrates a robust pipeline for:

Multilingual voice input handling.

Accurate transcription and translation.

Semantic QA with structured answer mapping.

Custom rule-based processing for real-world survey logic.

This lays a strong foundation for a scalable, AI-powered, real-time survey assistant.

âœ… Phase 2: Enhancements & Fixes

Standardized question format to match Confluence documentation and updated the codebase accordingly.

Added new test questions to expand QA coverage.

Faced challenges with questions having predefined options, where model predictions (e.g., â€œ200 mlâ€) didnâ€™t exactly match options (e.g., â€œ< 250 mlâ€).

Example fixes:

Oil Consumption: â€œ200 mlâ€ â†’ mapped to "< 250 ml"

Meal Timing: â€œaround seven in the eveningâ€ â†’ mapped to "Before 7:00 PM".

Achieved higher accuracy by combining model outputs with rule-based mapping and contextual cues.
